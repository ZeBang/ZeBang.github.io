{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Convolutional Neural Networks\n",
    "\n",
    "In this assignment, you will first implement the forward and backward pass of a convolution layer. Then you can freely design your own CNN model for image classification on CIFAR-10.\n",
    "\n",
    "As in previous assignments, you will see code blocks that look like this:\n",
    "```python\n",
    "###############################################################################\n",
    "# TODO: Create a variable x with value 536.                                   #\n",
    "###############################################################################\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "# END OF YOUR CODE\n",
    "```\n",
    "\n",
    "You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n",
    "```python\n",
    "###############################################################################\n",
    "# TODO: Create a variable x with value 536.                                   #\n",
    "###############################################################################\n",
    "# Replace \"pass\" statement with your code\n",
    "x = 536\n",
    "# END OF YOUR CODE\n",
    "```\n",
    "\n",
    "Also, please remember:\n",
    "- Do not write or modify any code outside of code blocks unless otherwise stated.\n",
    "- Do not delete any cells from the notebook. You may add new cells to perform scratch work, but delete them before submitting.\n",
    "- Run all cells before submitting. You will only get credit for code that has been run.\n",
    "- Submit your notebook as `netid.ipynb`, where `netid` is your actual netid.\n",
    "- Your submission will be graded with PyTorch 1.7.0 and Python 3.6, which are the default versions in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf34ad455b5599831d0f347f7dfe89b1",
     "grade": false,
     "grade_id": "cell-457536641359aba7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), 'GPU unavailable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution - Forward Pass\n",
    "\n",
    "Let us first implement the forward pass of 2D convolution and get a better understanding of the operations it performs. We will be replicating the functionality of PyTorch's built-in 2D convolution: [`nn.Conv2d()`](https://pytorch.org/docs/1.7.0/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) and [`F.conv2d()`](https://pytorch.org/docs/1.7.0/nn.functional.html#torch.nn.functional.conv2d). Please refer to the documentation for more details of the input arguments and return values. It is acceptable to use nested loops here, but you may also develop a vectorized implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "243f148b54cbfb302bf3b5a19c816739",
     "grade": false,
     "grade_id": "cell-957ee57959788d31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def conv2d(input, weight, bias=None, stride=1, padding=0):\n",
    "  \"\"\"\n",
    "  Apply 2D convolution over a batch of input tensors.\n",
    "  \n",
    "  Input arguments and return value are the same as those of F.conv2d(),\n",
    "  except that we don't care about `dilation` and `groups` here.\n",
    "  Also, `padding_mode` is `zeros`.\n",
    "  \"\"\"\n",
    "  output = None\n",
    "  #############################################################################\n",
    "  # TODO: Implement the same functionality as F.conv2d(). You are NOT allowed #\n",
    "  # to use F.conv2d() or nn.Conv2d().                                         #\n",
    "  #############################################################################\n",
    "  # Replace \"pass\" statement with your code\n",
    "  x = input\n",
    "  w = weight\n",
    "  b = bias\n",
    "  N, C, H, W = x.shape\n",
    "  F, _, HH, WW = w.shape\n",
    "  pad = padding\n",
    "  if isinstance(pad, int):\n",
    "   pad = (pad, pad)\n",
    "  if isinstance(stride, int):\n",
    "   stride = (stride, stride)\n",
    "  # Check for parameter sanity\n",
    "#   assert (H + 2 * pad - HH) % stride == 0, 'Sanity Check Status: Conv Layer Failed in Height'\n",
    "#   assert (W + 2 * pad - WW) % stride == 0, 'Sanity Check Status: Conv Layer Failed in Width'\n",
    "  H_prime = 1 + (H + 2 * pad[0] - HH) // stride[0]\n",
    "  W_prime = 1 + (W + 2 * pad[1] - WW) // stride[1]\n",
    "  # Padding\n",
    "  # x_pad = np.pad(x, ((0, 0), (0, 0), (pad, pad), (pad, pad)), 'constant', constant_values=0)\n",
    "  x_pad = torch.nn.functional.pad(x, (pad[1],pad[1],pad[0],pad[0])).to(x.dtype).to(x.device)\n",
    "  # Construct output\n",
    "  out = torch.zeros((N, F, H_prime, W_prime)).to(x.dtype).to(x.device)\n",
    "  # Naive Loops\n",
    "  for n in range(N):\n",
    "      for f in range(F):\n",
    "          for j in range(0, H_prime):\n",
    "              for i in range(0, W_prime):\n",
    "                if b is None:\n",
    "                  out[n, f, j, i] = (x_pad[n, :, j*stride[0]:j*stride[0]+HH, i*stride[1]:i*stride[1]+WW] * w[f, :, :, :]).sum()\n",
    "                else:\n",
    "                  out[n, f, j, i] = (x_pad[n, :, j*stride[0]:j*stride[0]+HH, i*stride[1]:i*stride[1]+WW] * w[f, :, :, :]).sum() + b[f]\n",
    "  output = out\n",
    "  # END OF YOUR CODE\n",
    "  \n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following helper functions to check your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "480efd5d1335218872603dbbfd812846",
     "grade": false,
     "grade_id": "cell-9e72cadefa119878",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def max_diff(actual, expected):\n",
    "  return (actual - expected).abs().max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "699256b7a25ce7cfb418ef4d07acdd6e",
     "grade": false,
     "grade_id": "cell-31c14321c924916f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def check_conv2d(batch_size, in_channels, in_height, in_width,\n",
    "                 out_channels, kernel_size, stride=1, padding=0, use_bias=True):\n",
    "  \n",
    "  if isinstance(kernel_size, int):\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "  \n",
    "  torch.manual_seed(0)\n",
    "  input = torch.empty(batch_size, in_channels, in_height, in_width).normal_()\n",
    "  weight = torch.empty(out_channels, in_channels, kernel_size[0], kernel_size[1]).normal_()\n",
    "  if use_bias:\n",
    "    bias = torch.empty(out_channels).normal_()\n",
    "  else:\n",
    "    bias = None\n",
    "  \n",
    "  actual = conv2d(input, weight, bias, stride, padding)\n",
    "  expected = F.conv2d(input, weight, bias, stride, padding)\n",
    "  assert actual.shape == expected.shape, 'incorrect shape'\n",
    "  \n",
    "  diff = max_diff(actual, expected)\n",
    "  print('max_diff = %e' % diff)\n",
    "  assert diff < 1e-3, 'incorrect result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b01d5a0097f10c80e9e19882d45c3738",
     "grade": true,
     "grade_id": "cell-14bbd8699f655aa6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_diff = 3.814697e-06\n"
     ]
    }
   ],
   "source": [
    "# check `kernel_size`\n",
    "check_conv2d(batch_size=8, in_channels=3, in_height=8, in_width=8,\n",
    "             out_channels=8, kernel_size=3, stride=1, padding=0, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52ea0353695cf1941ffb156c5a7fbc19",
     "grade": true,
     "grade_id": "cell-7da6585224c9bed0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_diff = 1.335144e-05\n"
     ]
    }
   ],
   "source": [
    "# check `stride`\n",
    "check_conv2d(batch_size=4, in_channels=8, in_height=16, in_width=16,\n",
    "             out_channels=3, kernel_size=5, stride=3, padding=0, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c99bd48315ec8dcb30b437dd83cbb3cc",
     "grade": true,
     "grade_id": "cell-570f56fc2d3fd7e0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_diff = 3.814697e-06\n"
     ]
    }
   ],
   "source": [
    "# check `padding`\n",
    "check_conv2d(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "             out_channels=4, kernel_size=8, stride=5, padding=3, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e0f79284d5b659c0b52113d975aee3c",
     "grade": true,
     "grade_id": "cell-6442ae8611d9de1f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_diff = 9.536743e-07\n"
     ]
    }
   ],
   "source": [
    "# check tuple arguments\n",
    "check_conv2d(batch_size=16, in_channels=4, in_height=4, in_width=8,\n",
    "             out_channels=1, kernel_size=(1, 3), stride=(1, 2), padding=(0, 1), use_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution - Backward Pass\n",
    "\n",
    "In order to train a CNN, we need to backpropagate the gradient through the convolution. More precisely, suppose we have performed a convolution:\n",
    "$$\n",
    "\\text{output} = \\text{conv2d}(\\text{input}, \\text{weight}, \\text{bias}),\n",
    "$$\n",
    "and the loss is defined as some function of the output:\n",
    "$$\n",
    "\\mathcal{L} = f(\\text{output}).\n",
    "$$\n",
    "Note that $\\text{output}, \\text{input}, \\text{weight}, \\text{bias}$ are tensors, and $\\mathcal{L}$ is a scalar.\n",
    "\n",
    "We need the gradients $\\frac{\\partial \\mathcal{L}}{\\partial \\text{weight}}$ and $\\frac{\\partial \\mathcal{L}}{\\partial \\text{bias}}$, which can be computed by the chain rule:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\text{weight}_i} &= \\sum_{k} \\frac{\\partial \\mathcal{L}}{\\partial \\text{output}_k} \\frac{\\partial \\text{output}_k}{\\partial \\text{weight}_i},\\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\text{bias}_j} &= \\sum_{k} \\frac{\\partial \\mathcal{L}}{\\partial \\text{output}_k} \\frac{\\partial \\text{output}_k}{\\partial \\text{bias}_j}.\n",
    "\\end{align}\n",
    "$$\n",
    "If $\\text{input}$ is computed by another neural network with parameters $\\theta$, then to obtain $\\frac{\\partial \\mathcal{L}}{\\partial \\theta}$, we also need $\\frac{\\partial \\mathcal{L}}{\\partial \\text{input}}$.\n",
    "\n",
    "Therefore, in the backward pass that we will implement below, given $\\frac{\\partial \\mathcal{L}}{\\partial \\text{output}}$, we need to compute $\\frac{\\partial \\mathcal{L}}{\\partial \\text{input}}$, $\\frac{\\partial \\mathcal{L}}{\\partial \\text{weight}}$, and $\\frac{\\partial \\mathcal{L}}{\\partial \\text{bias}}$.\n",
    "\n",
    "You are NOT allowed to use PyTorch's automatic differentiation, but you may use other built-in functions (in particular, [`F.conv2d()`](https://pytorch.org/docs/1.7.0/nn.functional.html#torch.nn.functional.conv2d) and [`F.conv_transpose2d()`](https://pytorch.org/docs/1.7.0/nn.functional.html#torch.nn.functional.conv_transpose2d)) if they can simplify your implementation. For simplicity, you only need to consider the case where `stride = 1`. You will get bonus points if your implementation also works for `stride > 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce47fe4fe96f2e6210cb5af4226dfdf2",
     "grade": false,
     "grade_id": "cell-ea3dc2ec1a2d8acf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def conv2d_grad(output_grad, input, weight, bias=None, stride=1, padding=0):\n",
    "  \"\"\"\n",
    "  Backward pass of 2D convolution.\n",
    "  \n",
    "  Inputs:\n",
    "  - output_grad: A PyTorch tensor giving the gradient of loss wrt `output`\n",
    "    computed by the forward pass conv2d(). It has the same shape as `output`.\n",
    "  - Other arguments are the same as those of conv2d().\n",
    "  \n",
    "  Returns:\n",
    "  - input_grad: A PyTorch tensor giving the gradient of loss wrt `input`.\n",
    "    It has the same shape as `input`.\n",
    "  - weight_grad: A PyTorch tensor giving the gradient of loss wrt `weight`.\n",
    "    It has the same shape as `weight`.\n",
    "  - bias_grad: A PyTorch tensor giving the gradient of loss wrt `bias`.\n",
    "    It has the same shape as `bias` if `bias` is not `None`.\n",
    "    Otherwise, it is `None`.\n",
    "  \"\"\"\n",
    "  input_grad = None\n",
    "  weight_grad = None\n",
    "  bias_grad = None\n",
    "  #############################################################################\n",
    "  # TODO: Implement the backward pass of conv2d(). You are NOT allowed to use #\n",
    "  # PyTorch's automatic differentiation.                                      #\n",
    "  #############################################################################\n",
    "  # Replace \"pass\" statement with your code\n",
    "  dout, x, w, b = output_grad, input, weight, bias\n",
    "  N, C, H, W = x.shape\n",
    "  F, _, HH, WW = w.shape\n",
    "  pad = padding\n",
    "  if isinstance(pad, int):\n",
    "   pad = (pad, pad)\n",
    "  if isinstance(stride, int):\n",
    "   stride = (stride, stride)\n",
    "  # Padding\n",
    "  x_pad = torch.nn.functional.pad(x, (pad[1],pad[1],pad[0],pad[0])).to(x.dtype).to(x.device)\n",
    "  H_prime = 1 + (H + 2 * pad[0] - HH) // stride[0]\n",
    "  W_prime = 1 + (W + 2 * pad[1] - WW) // stride[1]\n",
    "  # Construct output\n",
    "  dx_pad = torch.zeros_like(x_pad).to(x.dtype).to(x.device)\n",
    "  input_grad = torch.zeros_like(x).to(x.dtype).to(x.device)\n",
    "  weight_grad = torch.zeros_like(w).to(x.dtype).to(x.device)\n",
    "  bias_grad = torch.zeros_like(b).to(x.dtype).to(x.device)\n",
    "  # Naive Loops\n",
    "  for n in range(N):\n",
    "      for f in range(F):\n",
    "          bias_grad[f] += torch.sum(dout[n, f])\n",
    "          for j in range(0, H_prime):\n",
    "              for i in range(0, W_prime):\n",
    "                  weight_grad[f] += x_pad[n, :, j * stride[0]:j * stride[0] + HH, i * stride[1]:i * stride[1] + WW] * dout[n, f, j, i]\n",
    "                  dx_pad[n, :, j * stride[0]:j * stride[0] + HH, i * stride[1]:i * stride[1] + WW] += w[f] * dout[n, f, j, i]\n",
    "    # Extract dx from dx_pad\n",
    "  input_grad = dx_pad[:, :, pad[0]:pad[0]+H, pad[1]:pad[1]+W]\n",
    "  # END OF YOUR CODE\n",
    "  return input_grad, weight_grad, bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check correctness, let us define a simple loss function:\n",
    "$$\n",
    "\\mathcal{L} = f(\\text{output}) = \\sum_k \\text{output}_k,\n",
    "$$\n",
    "so that for each element in the output,\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\text{output}_k} = 1.\n",
    "$$\n",
    "Hence, we can use a tensor of ones for `output_grad`.\n",
    "\n",
    "We will compare the returned gradients with those computed by PyTorch's automatic differentiation. To use automatic differentiation:\n",
    "- Create tensors with `requires_grad=True`. PyTorch will automatically build up a computational graph of operations involving those tensors.\n",
    "- Compute the loss (forward pass).\n",
    "- Call `loss.backward()`. PyTorch will use backpropagation to compute the gradient of the loss wrt the tensors in the computational graph. The gradient is stored in the `.grad` attribute of each tensor.\n",
    "\n",
    "We will use the following helper functions to check your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1477f20491756b9fd63192334d621e54",
     "grade": false,
     "grade_id": "cell-dcc4f5ea953cadef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def max_rel_error(actual, expected):\n",
    "  \n",
    "  rel_error_top = (actual - expected).abs()\n",
    "  rel_error_bot = actual.abs() + expected.abs() + 1e-7\n",
    "  return (rel_error_top / rel_error_bot).max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f777f2f651892fb98cc1495fe5d97f4e",
     "grade": false,
     "grade_id": "cell-e869328c980614f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def check_conv2d_grad(batch_size, in_channels, in_height, in_width,\n",
    "                      out_channels, kernel_size, stride=1, padding=0, use_bias=True,\n",
    "                      variable='input'):\n",
    "  \n",
    "  if isinstance(kernel_size, int):\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "  \n",
    "  torch.manual_seed(0)\n",
    "  input = torch.empty(batch_size, in_channels, in_height, in_width).normal_()\n",
    "  weight = torch.empty(out_channels, in_channels, kernel_size[0], kernel_size[1]).normal_()\n",
    "  if use_bias:\n",
    "    bias = torch.empty(out_channels).normal_()\n",
    "  else:\n",
    "    bias = None\n",
    "  \n",
    "  output = F.conv2d(input, weight, bias, stride, padding)\n",
    "  output_grad = torch.ones_like(output)\n",
    "  \n",
    "  input_grad, weight_grad, bias_grad = conv2d_grad(\n",
    "    output_grad, input, weight, bias, stride, padding)\n",
    "  \n",
    "  # Use automatic differentiation to compute gradients\n",
    "  # 1. Set `requires_grad` to `True`\n",
    "  input.requires_grad_()\n",
    "  weight.requires_grad_()\n",
    "  if use_bias:\n",
    "    bias.requires_grad_()\n",
    "  \n",
    "  # 2. Compute loss\n",
    "  output = F.conv2d(input, weight, bias, stride, padding)\n",
    "  loss = output.sum()\n",
    "  \n",
    "  # 3. Backpropagation\n",
    "  loss.backward()\n",
    "  # The gradients are stored in `input.grad`, `weight.grad`, and `bias.grad`\n",
    "  \n",
    "  if variable == 'input':\n",
    "    assert input_grad.shape == input.grad.shape, 'incorrect shape'\n",
    "    rel_error = max_rel_error(input_grad, input.grad)\n",
    "    print('relative error = %e' % rel_error)\n",
    "    assert rel_error < 1e-3, 'incorrect result'\n",
    "  elif variable == 'weight':\n",
    "    assert weight_grad.shape == weight.grad.shape, 'incorrect shape'\n",
    "    rel_error = max_rel_error(weight_grad, weight.grad)\n",
    "    print('relative error = %e' % rel_error)\n",
    "    assert rel_error < 1e-3, 'incorrect result'\n",
    "  else:\n",
    "    if not use_bias:\n",
    "      assert bias_grad is None\n",
    "    else:\n",
    "      assert bias_grad.shape == bias.grad.shape, 'incorrect shape'\n",
    "      rel_error = max_rel_error(bias_grad, bias.grad)\n",
    "      print('relative error = %e' % rel_error)\n",
    "      assert rel_error < 1e-3, 'incorrect result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91e133d66fa1fb58f6d90786c59283c0",
     "grade": true,
     "grade_id": "cell-ba74d1d74eb556e1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 6.217231e-07\n"
     ]
    }
   ],
   "source": [
    "# check `kernel_size`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=8, in_width=8,\n",
    "                  out_channels=1, kernel_size=3, stride=1, padding=0, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a1a8909100f88f1d909fa1be58c66b3",
     "grade": true,
     "grade_id": "cell-6c2c6516844a2598",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 1.121814e-07\n"
     ]
    }
   ],
   "source": [
    "# check `kernel_size`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=8, in_width=8,\n",
    "                  out_channels=1, kernel_size=3, stride=1, padding=0, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d08ee5fc51f8bd7c94710705a04df45",
     "grade": true,
     "grade_id": "cell-8712e8d7fc1fd48e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `kernel_size`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=8, in_width=8,\n",
    "                  out_channels=1, kernel_size=3, stride=1, padding=0, use_bias=True,\n",
    "                  variable='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9e0e32c13c71c4d235d19dc26f548a6",
     "grade": true,
     "grade_id": "cell-3dba9bf15404b942",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 4.184267e-07\n"
     ]
    }
   ],
   "source": [
    "# check `padding`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "                  out_channels=1, kernel_size=8, stride=1, padding=3, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ef14022a663b55ff47ec05c4785b6aa",
     "grade": true,
     "grade_id": "cell-adcde4921714635f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `padding`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "                  out_channels=1, kernel_size=8, stride=1, padding=3, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a75d966ad81a691c3d9067aff6fb585",
     "grade": true,
     "grade_id": "cell-4b909b84dae0955e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `padding`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "                  out_channels=1, kernel_size=8, stride=1, padding=3, use_bias=True,\n",
    "                  variable='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d16b5d6b637138f5255291f556f5c8f",
     "grade": true,
     "grade_id": "cell-a6413b60fea862e1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `in_channels`\n",
    "check_conv2d_grad(batch_size=1, in_channels=8, in_height=8, in_width=8,\n",
    "                  out_channels=1, kernel_size=1, stride=1, padding=0, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "118164a056ca487de8ae0f34299bddee",
     "grade": true,
     "grade_id": "cell-72c432fc0fe21f76",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 1.820473e-07\n"
     ]
    }
   ],
   "source": [
    "# check `in_channels`\n",
    "check_conv2d_grad(batch_size=1, in_channels=8, in_height=8, in_width=8,\n",
    "                  out_channels=1, kernel_size=1, stride=1, padding=0, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f84c1c742e1fb50d62c3c69aaed7d07",
     "grade": true,
     "grade_id": "cell-22d17a84fd588b6b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `in_channels`\n",
    "check_conv2d_grad(batch_size=1, in_channels=8, in_height=8, in_width=8,\n",
    "                  out_channels=1, kernel_size=1, stride=1, padding=0, use_bias=True,\n",
    "                  variable='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be9d325d9191b26100c5bac56a32002a",
     "grade": true,
     "grade_id": "cell-72bab9f4cfb37050",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 3.272701e-06\n"
     ]
    }
   ],
   "source": [
    "# check `out_channels`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "                  out_channels=2, kernel_size=9, stride=1, padding=2, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a92d9d915741a8d735d3ee0f4397d240",
     "grade": true,
     "grade_id": "cell-1aa88d792e62a919",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `out_channels`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "                  out_channels=2, kernel_size=9, stride=1, padding=2, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04e019c13d8c2671a8013cf16fa8dc3a",
     "grade": true,
     "grade_id": "cell-e1730da18da44d61",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `out_channels`\n",
    "check_conv2d_grad(batch_size=1, in_channels=1, in_height=32, in_width=32,\n",
    "                  out_channels=2, kernel_size=9, stride=1, padding=2, use_bias=True,\n",
    "                  variable='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1664a3f2ec1a2f90e7b715c46cc16f2",
     "grade": true,
     "grade_id": "cell-723b558a132a75a3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 1.685663e-07\n"
     ]
    }
   ],
   "source": [
    "# check `batch_size`\n",
    "check_conv2d_grad(batch_size=8, in_channels=1, in_height=16, in_width=16,\n",
    "                  out_channels=1, kernel_size=5, stride=1, padding=3, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7af6f5384f84c07ae29cbd7e748cabe6",
     "grade": true,
     "grade_id": "cell-1a5d7e9537db4632",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 1.089569e-06\n"
     ]
    }
   ],
   "source": [
    "# check `batch_size`\n",
    "check_conv2d_grad(batch_size=8, in_channels=1, in_height=16, in_width=16,\n",
    "                  out_channels=1, kernel_size=5, stride=1, padding=3, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b458c740b8a8a7e1e9a535efb18b874",
     "grade": true,
     "grade_id": "cell-7fa8371f43538291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check `batch_size`\n",
    "check_conv2d_grad(batch_size=8, in_channels=1, in_height=16, in_width=16,\n",
    "                  out_channels=1, kernel_size=5, stride=1, padding=3, use_bias=True,\n",
    "                  variable='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b41fead94cc307921f34c1711eaf17a",
     "grade": true,
     "grade_id": "cell-c5c0eee462672ab7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 7.630093e-07\n"
     ]
    }
   ],
   "source": [
    "# check tuple arguments\n",
    "check_conv2d_grad(batch_size=16, in_channels=4, in_height=4, in_width=8,\n",
    "                  out_channels=8, kernel_size=(1, 3), stride=1, padding=1, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d562436c69df1e13d020dcd960f6300e",
     "grade": true,
     "grade_id": "cell-7c94baa251ace3bd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 2.305379e-05\n"
     ]
    }
   ],
   "source": [
    "# check tuple arguments\n",
    "check_conv2d_grad(batch_size=16, in_channels=4, in_height=4, in_width=8,\n",
    "                  out_channels=8, kernel_size=(1, 3), stride=1, padding=1, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fc5abd9f623002fa3c1c6a52ae4e688",
     "grade": true,
     "grade_id": "cell-153442a921a5a2f6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# check tuple arguments\n",
    "check_conv2d_grad(batch_size=16, in_channels=4, in_height=4, in_width=8,\n",
    "                  out_channels=8, kernel_size=(1, 3), stride=1, padding=1, use_bias=True,\n",
    "                  variable='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS: `stride > 1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ecbb084cf4c750e3cc1d6100fc8f89",
     "grade": true,
     "grade_id": "cell-8279eb351843834a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 3.424135e-07\n"
     ]
    }
   ],
   "source": [
    "# check `stride`\n",
    "check_conv2d_grad(batch_size=16, in_channels=4, in_height=4, in_width=8,\n",
    "                  out_channels=8, kernel_size=(1, 3), stride=(1, 2), padding=1, use_bias=True,\n",
    "                  variable='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2eeca5956b6d76e6570e1495b8658efe",
     "grade": true,
     "grade_id": "cell-9402e9681a8ccd08",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative error = 3.018977e-06\n"
     ]
    }
   ],
   "source": [
    "# check `stride`\n",
    "check_conv2d_grad(batch_size=16, in_channels=4, in_height=4, in_width=8,\n",
    "                  out_channels=8, kernel_size=(1, 3), stride=(1, 2), padding=1, use_bias=True,\n",
    "                  variable='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Open-Ended Challenge\n",
    "\n",
    "In this section, you can experiment with whatever CNN architecture you'd like on CIFAR-10. Your model should be able to **achieve at least 75% validation accuracy** within 10-20 epochs.\n",
    "\n",
    "This [tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) will walk you through the process of training a CNN classifier using PyTorch. The model used in this tutorial, however, is too simple for our purpose. To conveniently create a deeper model, you can use [`nn.Sequential()`](https://pytorch.org/docs/1.7.0/generated/torch.nn.Sequential.html#torch.nn.Sequential) to stack multiple layers together. You can use built-in layers in the [`torch.nn`](https://pytorch.org/docs/1.7.0/nn.html) package, or you can develop custom layers. All custom layers should subclass [`nn.Module`](https://pytorch.org/docs/1.7.0/generated/torch.nn.Module.html#torch.nn.Module).\n",
    "\n",
    "### Things you might try\n",
    "- **Network architecture**: [VGG](https://arxiv.org/abs/1409.1556) can be a good starting point. Keep in mind that this model is designed for ImageNet, which is much larger and have a different image resolution than CIFAR-10. You need to make some adaptations. For example, you may tweak the number of layers and number of channels. [ResNet](https://arxiv.org/abs/1512.03385) and [DenseNet](https://arxiv.org/abs/1608.06993) are also good architectures to try.\n",
    "- **Batch normalization**: You can conveniently add batch normalization layers using [`nn.BatchNorm2d()`](https://pytorch.org/docs/1.7.0/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d). Does your model train faster with batch normalization?\n",
    "- **Optimizer**: The [`torch.optim`](https://pytorch.org/docs/1.7.0/optim.html) package implements many optimization algorithms that you can try, such as [SGD](https://pytorch.org/docs/1.7.0/optim.html#torch.optim.SGD), [Adam](https://pytorch.org/docs/1.7.0/optim.html#torch.optim.Adam), and [RMSprop](https://pytorch.org/docs/1.7.0/optim.html#torch.optim.RMSprop).\n",
    "- **Regularization**: You may use weight decay or [Dropout](https://pytorch.org/docs/1.7.0/generated/torch.nn.Dropout.html#torch.nn.Dropout) to reduce overfitting.\n",
    "- **Activation**: In addition to [ReLU](https://pytorch.org/docs/1.7.0/generated/torch.nn.ReLU.html#torch.nn.ReLU), some recent papers also use [ELU](https://pytorch.org/docs/1.7.0/generated/torch.nn.ELU.html#torch.nn.ELU) and [GELU](https://pytorch.org/docs/1.7.0/generated/torch.nn.GELU.html#torch.nn.GELU). Can they improve your model's performance?\n",
    "- **Pooling vs Strided Convolution**: Similar to pooling, strided convolution can reduce the spatial size of feature maps. However, strided convolution contains learnable parameters, which make the model more flexible. Does strided convolution lead to improved performance?\n",
    "- **Flattening vs Global Average Pooling**: [GoogLeNet](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf), [ResNet](https://arxiv.org/abs/1512.03385), and [DenseNet](https://arxiv.org/abs/1608.06993) all use global average pooling followed by a single linear layer to produce the class probabilities from the last feature map. How does this compare to the traditional approach of flattening the last feature map and then having several fully connected layers?\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and other hyperparameters using the validation set. Remember the coarse-to-fine strategy.\n",
    "\n",
    "### Have fun and happy training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We will use the precomputed RGB mean and standard deviation to normalize the images. We then use PyTorch's built-in [`DataLoader`](https://pytorch.org/docs/1.7.0/data.html#torch.utils.data.DataLoader) for automatic mini-batch sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65d8c9b86d59f02931ede7a34a91568d",
     "grade": false,
     "grade_id": "cell-37df95f191c6272e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders():\n",
    "  \"\"\"\n",
    "  Normalize the data and split into (train 40K)/(val 10K)/(test 10K).\n",
    "  \n",
    "  Returns:\n",
    "  - PyTorch DataLoaders that can automatically sample mini-batches.\n",
    "  \"\"\"\n",
    "  loader_kwargs = {\n",
    "    'batch_size': 100,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    'drop_last': True,\n",
    "  }\n",
    "  \n",
    "  transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2470, 0.2435, 0.2616]),\n",
    "  ])\n",
    "  \n",
    "  CIFAR10_train = CIFAR10(root='.', train=True, transform=transform, download=True)\n",
    "  CIFAR10_test = CIFAR10(root='.', train=False, transform=transform, download=True)\n",
    "  \n",
    "  train_set, val_set = random_split(CIFAR10_train, [40000, 10000],\n",
    "                                    generator=torch.Generator().manual_seed(0))\n",
    "  \n",
    "  train_loader = DataLoader(train_set, **loader_kwargs)\n",
    "  val_loader = DataLoader(val_set, **loader_kwargs)\n",
    "  test_loader = DataLoader(CIFAR10_test, **loader_kwargs)\n",
    "  \n",
    "  return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Implement your CNN model below. If you implemented multiple models, you only need to show the best one. You may add helper functions and custom modules as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaa4037c0d5f3e6dfc74cbfe66c5f8c5",
     "grade": false,
     "grade_id": "cell-e5e9f791f46ad5e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # Specify your model architecture.                                      #\n",
    "    #########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "    self.conv15 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    self.pooling = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(64, 128 , 3, padding=1)\n",
    "    self.conv25 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "    self.conv3 = nn.Conv2d(128, 256 , 3, padding=1)\n",
    "    self.conv35 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "    self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 512)\n",
    "    self.fc3 = nn.Linear(512, 10)\n",
    "    self.m1 = nn.Sequential(self.conv1,nn.ReLU(),self.conv15,nn.BatchNorm2d(64),nn.ReLU(),self.pooling,nn.Dropout2d(p=0.1),\n",
    "                                  self.conv2,nn.ReLU(),self.conv25,nn.BatchNorm2d(128),nn.ReLU(),self.pooling,nn.Dropout2d(p=0.1),\n",
    "                                  self.conv3,nn.ReLU(),self.conv35,nn.BatchNorm2d(256),nn.ReLU(),self.pooling)\n",
    "    self.m2 = nn.Sequential(self.fc1,nn.ReLU(),self.fc2,nn.ReLU(),self.fc3)\n",
    "    # END OF YOUR CODE\n",
    "  \n",
    "  \n",
    "  def forward(self, images, labels):\n",
    "    \"\"\"\n",
    "    Compute the loss for a mini-batch of training samples.\n",
    "    \n",
    "    Inputs:\n",
    "    - images: A PyTorch tensor of shape (B, 3, 32, 32) containing\n",
    "      a mini-batch of B training images.\n",
    "    - labels: A PyTorch tensor of shape (B,) containing the corresponding\n",
    "      training labels; labels[i] = k means that images[i] has label k,\n",
    "      where 0 <= k < 10.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: A PyTorch scalar giving the training loss of this mini-batch.\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # Implement the forward pass.                                           #\n",
    "    #########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    x = self.m1(images)\n",
    "    x = x.view(100,-1)\n",
    "    x = self.m2(x)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(x, labels)\n",
    "    # END OF YOUR CODE\n",
    "    return loss\n",
    "  \n",
    "  \n",
    "  def predict(self, images):\n",
    "    \"\"\"\n",
    "    Predict the labels for a mini-batch of images.\n",
    "    \n",
    "    Inputs:\n",
    "    - images: A PyTorch tensor of shape (B, 3, 32, 32) containing\n",
    "      a mini-batch of B images.\n",
    "    \n",
    "    Returns:\n",
    "    - labels_pred: A PyTorch tensor of shape (B,) containing the predicted\n",
    "      labels; labels_pred[i] = k means that k is the predicted label for\n",
    "      images[i], where 0 <= k < 10.\n",
    "    \"\"\"\n",
    "    labels_pred = None\n",
    "    #########################################################################\n",
    "    # TODO:                                                                 #\n",
    "    # Implement the prediction phase.                                       #\n",
    "    #########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    x = self.m1(images)\n",
    "    x = x.view(100,-1)\n",
    "    x = self.m2(x)\n",
    "    labels_pred = torch.argmax(x, dim=1)\n",
    "    # END OF YOUR CODE\n",
    "    return labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We will use the following function to evaluate the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0506d61454a231c261204096aecb66b",
     "grade": false,
     "grade_id": "cell-8ea391396f07eb1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def eval_acc(model, data_loader):\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for (images, labels) in data_loader:\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "      \n",
    "      labels_pred = model.predict(images)\n",
    "      \n",
    "      total += labels.shape[0]\n",
    "      correct += (labels_pred == labels).sum().item()\n",
    "    \n",
    "    acc = 100 * correct / total\n",
    "  \n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "A basic training script is provided below. You can make modifications as appropriate. For example, you can save the model that achieves the best validation accuracy (instead of always using the latest model). Also, you may use learning rate schedules and gradient clipping. Only keep the best hyperparameters that you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch:   0 \t Loss: 2.330870 \t Val Acc: 10.050000\n",
      "Train Epoch:   1 \t Loss: 1.488392 \t Val Acc: 48.440000\n",
      "Train Epoch:   2 \t Loss: 1.123725 \t Val Acc: 60.150000\n",
      "Train Epoch:   3 \t Loss: 0.987762 \t Val Acc: 63.140000\n",
      "Train Epoch:   4 \t Loss: 0.903532 \t Val Acc: 67.360000\n",
      "Train Epoch:   5 \t Loss: 0.672511 \t Val Acc: 71.920000\n",
      "Train Epoch:   6 \t Loss: 0.709339 \t Val Acc: 72.390000\n",
      "Train Epoch:   7 \t Loss: 0.703429 \t Val Acc: 75.770000\n",
      "Train Epoch:   8 \t Loss: 0.519808 \t Val Acc: 76.490000\n",
      "Train Epoch:   9 \t Loss: 0.592181 \t Val Acc: 76.190000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "\n",
    "num_epochs = 10\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # TODO: choose an optimizer\n",
    "\n",
    "loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "  val_acc = eval_acc(model, val_loader)\n",
    "  \n",
    "  model.train()\n",
    "  \n",
    "  for batch, (images, labels) in enumerate(train_loader):\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = model(images, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      loss_history.append(loss.item())\n",
    "      if batch == 0:\n",
    "        print('Train Epoch: {:3} \\t Loss: {:F} \\t Val Acc: {:F}'.format(\n",
    "          epoch, loss.item(), val_acc))\n",
    "\n",
    "with torch.no_grad():\n",
    "  plt.plot(loss_history, 'o')\n",
    "  plt.xlabel('Iteration number')\n",
    "  plt.ylabel('Loss value')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 87.21\n"
     ]
    }
   ],
   "source": [
    "train_acc = eval_acc(model, train_loader)\n",
    "print('Training Accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82cb53992b3b46214bbd489d98dbdfa1",
     "grade": true,
     "grade_id": "cell-e1a810a12e065ec6",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.13\n"
     ]
    }
   ],
   "source": [
    "val_acc = eval_acc(model, val_loader)\n",
    "print('Validation Accuracy:', val_acc)\n",
    "assert val_acc >= 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 76.67\n"
     ]
    }
   ],
   "source": [
    "test_acc = eval_acc(model, test_loader)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
